{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "967e9985",
   "metadata": {},
   "source": [
    "$\\textbf{HOUSE SALE PRICES}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c4d3a4",
   "metadata": {},
   "source": [
    "This notebook shows a submission to the Housing Prices competition on Kaggle(https://www.kaggle.com/competitions/home-data-for-ml-course/overview), which aims to predict the final price of homes based on various features such as overall quality, year built, total area, and neighborhood.\n",
    "\n",
    "The entire workflow — from data loading and preprocessing to model training, tuning, and evaluation — is performed in this single Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3d471d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bf0dc8",
   "metadata": {},
   "source": [
    "Importing the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d639aaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA:\n",
      " \n",
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
      "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
      "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
      "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
      "\n",
      "  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0   2008        WD         Normal     208500  \n",
      "1   2007        WD         Normal     181500  \n",
      "2   2008        WD         Normal     223500  \n",
      "3   2006        WD        Abnorml     140000  \n",
      "4   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n",
      "\n",
      "\n",
      "TESTING DATA: \n",
      "\n",
      "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
      "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
      "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
      "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
      "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
      "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
      "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
      "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
      "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
      "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
      "\n",
      "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
      "0       0      6    2010        WD         Normal  \n",
      "1   12500      6    2010        WD         Normal  \n",
      "2       0      3    2010        WD         Normal  \n",
      "3       0      6    2010        WD         Normal  \n",
      "4       0      1    2010        WD         Normal  \n",
      "\n",
      "[5 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('./train.csv')\n",
    "test_data = pd.read_csv('./test.csv')\n",
    "print(\"TRAINING DATA:\\n \")\n",
    "print(train_data.head())\n",
    "print(\"\\n\\nTESTING DATA: \\n\")\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69623e73",
   "metadata": {},
   "source": [
    "$\\textbf{Data Preprocessing:}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52d355f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TRAINING DATA\n",
    "# Remove rows with missing target values\n",
    "X_train_full = train_data.dropna(axis=0, subset=['SalePrice'])\n",
    "\n",
    "# create target series and drop it from the deatures\n",
    "y_train_full = X_train_full['SalePrice']\n",
    "X_train_full.drop(columns=['SalePrice', 'Id'], axis=1, inplace=True)\n",
    "\n",
    "# Split the full data into training and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, random_state=0, train_size=0.8)\n",
    "\n",
    "# SIMILARLY FOR TESTING DATA\n",
    "X_test = test_data.drop(columns=['Id'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed037e",
   "metadata": {},
   "source": [
    "Checking The carinality of object columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2272f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MSZoning', 5),\n",
       " ('Street', 2),\n",
       " ('Alley', 2),\n",
       " ('LotShape', 4),\n",
       " ('LandContour', 4),\n",
       " ('Utilities', 2),\n",
       " ('LotConfig', 5),\n",
       " ('LandSlope', 3),\n",
       " ('Neighborhood', 25),\n",
       " ('Condition1', 9),\n",
       " ('Condition2', 6),\n",
       " ('BldgType', 5),\n",
       " ('HouseStyle', 8),\n",
       " ('RoofStyle', 6),\n",
       " ('RoofMatl', 7),\n",
       " ('Exterior1st', 15),\n",
       " ('Exterior2nd', 16),\n",
       " ('MasVnrType', 4),\n",
       " ('ExterQual', 4),\n",
       " ('ExterCond', 5),\n",
       " ('Foundation', 6),\n",
       " ('BsmtQual', 4),\n",
       " ('BsmtCond', 4),\n",
       " ('BsmtExposure', 4),\n",
       " ('BsmtFinType1', 6),\n",
       " ('BsmtFinType2', 6),\n",
       " ('Heating', 6),\n",
       " ('HeatingQC', 5),\n",
       " ('CentralAir', 2),\n",
       " ('Electrical', 5),\n",
       " ('KitchenQual', 4),\n",
       " ('Functional', 6),\n",
       " ('FireplaceQu', 5),\n",
       " ('GarageType', 6),\n",
       " ('GarageFinish', 3),\n",
       " ('GarageQual', 5),\n",
       " ('GarageCond', 5),\n",
       " ('PavedDrive', 3),\n",
       " ('PoolQC', 3),\n",
       " ('Fence', 4),\n",
       " ('MiscFeature', 3),\n",
       " ('SaleType', 9),\n",
       " ('SaleCondition', 6)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = [col for col in X_train if X_train[col].dtypes=='object']\n",
    "categorical_cardinalities = [X_train[col].nunique() for col in categorical_columns]\n",
    "d = dict(zip(categorical_columns, categorical_cardinalities))\n",
    "len(list(d.items()))\n",
    "(list(d.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4223bffb",
   "metadata": {},
   "source": [
    "Here, I choose to discard all columns where the cardinality is greater than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b910ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the low- (nunique<=10) and high- cardinality columns\n",
    "low_cardinality_cols = [col for col in categorical_columns if X_train[col].nunique()<=10]\n",
    "high_cardinality_cols = list(set(categorical_columns) - set(low_cardinality_cols))\n",
    "\n",
    "# Selecting the numeric columns:\n",
    "numeric_cols = [col for col in X_train if  train_data[col].dtypes=='int64' or train_data[col].dtypes=='float64']\n",
    "\n",
    "data_cols = numeric_cols + low_cardinality_cols\n",
    "X_train_reduced = X_train[data_cols].copy()\n",
    "X_val_reduced = X_val[data_cols].copy()\n",
    "X_test_reduced = X_test[data_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e91a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical preprocessing\n",
    "numerical_transformer = SimpleImputer(strategy='median')\n",
    "\n",
    "# categorical preprocessing\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numeric_cols),\n",
    "    ('cat', categorical_transformer, low_cardinality_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570ed148",
   "metadata": {},
   "source": [
    "$\\textbf{Building Models:}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a286217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the models\n",
    "models = {\n",
    "    'RandomForest' : RandomForestRegressor(random_state=0),\n",
    "    'XGBoost' : XGBRegressor(random_state=0),\n",
    "    'DecisionTree' : DecisionTreeRegressor(random_state=0)\n",
    "}\n",
    "\n",
    "# Defining the parameter lists for grid search\n",
    "grid_params = {\n",
    "    'RandomForest' : {\n",
    "        'model__n_estimators' : [50, 100, 200, 300, 400]\n",
    "    },\n",
    "    'XGBoost' : {\n",
    "        'model__n_estimators' : [50, 100, 200, 300, 400],\n",
    "        'model__learning_rate' : [0.03, 0.05, 0.08, 0.1]\n",
    "    },\n",
    "    'DecisionTree' : {\n",
    "        'model__max_leaf_nodes' : [10, 25, 50, 100, 200]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78221ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search running for RandomForest\n",
      "Best params for RandomForest is: {'model__n_estimators': 300}\n",
      "Best MAE for RandomForest is: 17787.56865868212\n",
      "Grid search running for XGBoost\n",
      "Best params for XGBoost is: {'model__learning_rate': 0.08, 'model__n_estimators': 300}\n",
      "Best MAE for XGBoost is: 16856.659375\n",
      "Grid search running for DecisionTree\n",
      "Best params for DecisionTree is: {'model__max_leaf_nodes': 200}\n",
      "Best MAE for DecisionTree is: 26049.260363094265\n"
     ]
    }
   ],
   "source": [
    "best_model_estimator = {}\n",
    "flag=-1\n",
    "\n",
    "# Fitting the models\n",
    "for name, model in models.items():\n",
    "    \n",
    "    flag+=1\n",
    "    print(\"Grid search running for {}\".format(name))\n",
    "\n",
    "    # A pipeline to run the models through\n",
    "    my_pipeline = Pipeline(steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # searching  for best fit aming the grid_params values\n",
    "    my_grid = GridSearchCV(my_pipeline, param_grid=grid_params[name],\n",
    "                            cv=5, n_jobs=None, scoring='neg_mean_absolute_error')\n",
    "    \n",
    "    my_grid.fit(X_train_reduced, y_train)\n",
    "\n",
    "    print(\"Best params for {} is: {}\".format(name, my_grid.best_params_))\n",
    "    print(\"Best MAE for {} is: {}\".format(name, -my_grid.best_score_))\n",
    "\n",
    "    # finding the single best estimator\n",
    "    if flag==0:\n",
    "        best_mae = -my_grid.best_score_\n",
    "        best_model = name\n",
    "        best_model_estimator[name] = my_grid.best_estimator_\n",
    "    elif -my_grid.best_score_ < best_mae:\n",
    "        best_model_estimator = {}\n",
    "        best_mae=-my_grid.best_score_\n",
    "        best_model = name\n",
    "        best_model_estimator[name] = my_grid.best_estimator_ \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2959a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE on the validaton set is : 17317.220703125\n"
     ]
    }
   ],
   "source": [
    "# Testing the best model on the validation dataset\n",
    "final_model = best_model_estimator[best_model]\n",
    "pred_y_val = final_model.predict(X_val_reduced)\n",
    "mae_final = mean_absolute_error(pred_y_val, y_val)\n",
    "print(\"The MAE on the validaton set is : {}\".format(mae_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95427457",
   "metadata": {},
   "source": [
    "$\\textbf{Final predictions on test dataset:}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8eb7b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = final_model.predict(X_test_reduced)\n",
    "\n",
    "# Exporting the data to a csv\n",
    "export_data = pd.DataFrame()\n",
    "export_data['Id'] = test_data.Id\n",
    "export_data['SalePrice'] = y_pred_final\n",
    "export_data.to_csv('./sale_price_prediction.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f7e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data = pd.DataFrame()\n",
    "export_data['Id'] = test_data.Id\n",
    "export_data['SalePrice'] = y_pred_final\n",
    "export_data.to_csv('./sale_price_prediction_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
